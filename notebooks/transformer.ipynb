{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "744ffb63",
      "metadata": {
        "id": "744ffb63"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import re\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9393e2be",
      "metadata": {
        "id": "9393e2be"
      },
      "outputs": [],
      "source": [
        "def calculate_sharpe(pnl_series, periods_per_year=390 * 252):\n",
        "    std = pnl_series.std()\n",
        "    if std == 0:\n",
        "        return 0.0\n",
        "    raw = pnl_series.mean() / std\n",
        "    return raw * np.sqrt(periods_per_year)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6893de",
      "metadata": {
        "id": "0c6893de"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "25bc30fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25bc30fd",
        "outputId": "938dc1be-c007-433a-eead-25cd6b647dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 2 rows with abnormal/NaN targets\n",
            "             datetime symbol     close   lret_1m  y_target\n",
            "0 2024-04-30 12:51:00   AMAT  200.5100 -0.000199 -0.000100\n",
            "1 2024-04-30 12:52:00   AMAT  200.4900 -0.000100  0.000149\n",
            "2 2024-04-30 12:53:00   AMAT  200.5198  0.000149  0.000549\n",
            "3 2024-04-30 12:54:00   AMAT  200.6300  0.000549 -0.000523\n",
            "4 2024-04-30 12:55:00   AMAT  200.5250 -0.000523  0.000175\n"
          ]
        }
      ],
      "source": [
        "DATA_PATH = Path('final_df.csv')\n",
        "if not DATA_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Cannot find {DATA_PATH}\")\n",
        "\n",
        "df_ori = pd.read_csv(DATA_PATH)\n",
        "df = df_ori.copy()\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df = df.sort_values(['symbol', 'datetime']).reset_index(drop=True)\n",
        "\n",
        "df['lret_1m'] = df.groupby('symbol')['close'].transform(lambda s: np.log(s).diff())\n",
        "df['y_target'] = df.groupby('symbol')['lret_1m'].shift(-1)\n",
        "\n",
        "initial_rows = len(df)\n",
        "df = df[df['y_target'].abs() <= 0.2].dropna(subset=['y_target', 'lret_1m'])\n",
        "df = df.sort_values(['datetime', 'symbol']).reset_index(drop=True)\n",
        "print(f\"Dropped {initial_rows - len(df)} rows with abnormal/NaN targets\")\n",
        "print(df[['datetime', 'symbol', 'close', 'lret_1m', 'y_target']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8abf98e0",
      "metadata": {
        "id": "8abf98e0"
      },
      "source": [
        "## Feature cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7e62bc02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e62bc02",
        "outputId": "39294fbe-e547-480e-9ede-98dbedd937d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original feature shape: (19111, 184)\n",
            "Dropping 53 problematic columns\n",
            "Cleaned feature shape: (19111, 131)\n"
          ]
        }
      ],
      "source": [
        "y = df['y_target']\n",
        "X = df.drop(columns=[\n",
        "    'y_target', 'lret_1m', 'datetime', 'symbol',\n",
        "    'year', 'month', 'day', 'minute', 'minute_of_day'\n",
        "], errors='ignore')\n",
        "print(f\"Original feature shape: {X.shape}\")\n",
        "\n",
        "stats = X.describe(percentiles=[0.99]).T\n",
        "bad_cols = set()\n",
        "bad_cols.update(stats.index[stats['std'] > 1e3])\n",
        "bad_cols.update(stats.index[stats['99%'].abs() > 1e3])\n",
        "bad_cols.update(stats.index[stats['max'].abs() > 1e6])\n",
        "bad_cols.update(stats.index[stats['std'] == 0])\n",
        "\n",
        "bad_cols = sorted(bad_cols)\n",
        "print(f\"Dropping {len(bad_cols)} problematic columns\")\n",
        "X_cleaned = X.drop(columns=bad_cols)\n",
        "print(f\"Cleaned feature shape: {X_cleaned.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c00fe9",
      "metadata": {
        "id": "d5c00fe9"
      },
      "source": [
        "## Train / test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "11810b4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11810b4e",
        "outputId": "82ae6c3b-b3d7-47dc-b2b6-cae191b9fcc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (12740, 131)\n",
            "Test shape:  (6371, 131)\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 1.0 / 1.5\n",
        "split_index = int(len(X_cleaned) * split_ratio)\n",
        "\n",
        "X_train = X_cleaned.iloc[:split_index]\n",
        "y_train = y.iloc[:split_index]\n",
        "X_test = X_cleaned.iloc[split_index:]\n",
        "y_test = y.iloc[split_index:]\n",
        "\n",
        "print(f\"Train shape: {X_train.shape}\")\n",
        "print(f\"Test shape:  {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bdc5abc",
      "metadata": {
        "id": "8bdc5abc"
      },
      "source": [
        "## Preprocessing pipeline\n",
        "\n",
        "Same as in LASSO, ridge regression notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a9c544e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9c544e7",
        "outputId": "58fc7194-553d-40f3-827e-e4c1fca2085b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete\n"
          ]
        }
      ],
      "source": [
        "class QuantileClipper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, lower=0.005, upper=0.995):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        self.q_low_ = None\n",
        "        self.q_high_ = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.q_low_ = np.nanpercentile(X, self.lower * 100, axis=0)\n",
        "        self.q_high_ = np.nanpercentile(X, self.upper * 100, axis=0)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.clip(X, self.q_low_, self.q_high_)\n",
        "\n",
        "feature_pipeline = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='median')),\n",
        "    ('clip', QuantileClipper(lower=0.005, upper=0.995)),\n",
        "    ('scale', MaxAbsScaler()),\n",
        "])\n",
        "\n",
        "feature_pipeline.fit(X_train)\n",
        "\n",
        "X_all_processed = pd.DataFrame(\n",
        "    feature_pipeline.transform(X_cleaned),\n",
        "    columns=X_cleaned.columns,\n",
        "    index=X_cleaned.index\n",
        ")\n",
        "\n",
        "print(\"Preprocessing complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3af7bb28",
      "metadata": {
        "id": "3af7bb28"
      },
      "outputs": [],
      "source": [
        "feature_cols = X_cleaned.columns.tolist()\n",
        "df_processed = X_all_processed.copy()\n",
        "df_processed[['datetime', 'symbol', 'y_target']] = df[['datetime', 'symbol', 'y_target']].values\n",
        "\n",
        "train_df = df_processed.iloc[:split_index].copy()\n",
        "test_df = df_processed.iloc[split_index:].copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca2ebc6",
      "metadata": {
        "id": "5ca2ebc6"
      },
      "source": [
        "## Sequence construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "65032ea9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65032ea9",
        "outputId": "bd39d982-e185-4967-da39-c574d264a04f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sequences: (12710, 30, 131)\n",
            "Test sequences:  (6341, 30, 131)\n"
          ]
        }
      ],
      "source": [
        "SEQ_LEN = 30\n",
        "PRED_HORIZON = 1\n",
        "\n",
        "\n",
        "def build_sequences(dataframe, feature_cols, target_col, seq_len=SEQ_LEN):\n",
        "    X_seq, y_seq, meta_dt, meta_symbol = [], [], [], []\n",
        "    for symbol, group in dataframe.groupby('symbol'):\n",
        "        group = group.sort_values('datetime')\n",
        "        feats = group[feature_cols].values\n",
        "        target = group[target_col].values\n",
        "        dts = group['datetime'].values\n",
        "        for i in range(len(group) - seq_len - PRED_HORIZON + 1):\n",
        "            start = i\n",
        "            end = i + seq_len\n",
        "            target_idx = end + PRED_HORIZON - 1\n",
        "            X_seq.append(feats[start:end])\n",
        "            y_seq.append(target[target_idx])\n",
        "            meta_dt.append(dts[target_idx])\n",
        "            meta_symbol.append(symbol)\n",
        "    return (\n",
        "        np.array(X_seq, dtype=np.float32),\n",
        "        np.array(y_seq, dtype=np.float32),\n",
        "        np.array(meta_dt),\n",
        "        np.array(meta_symbol)\n",
        "    )\n",
        "\n",
        "train_X_seq, train_y_seq, train_meta_dt, train_meta_sym = build_sequences(\n",
        "    train_df, feature_cols, 'y_target', seq_len=SEQ_LEN\n",
        ")\n",
        "\n",
        "test_X_seq, test_y_seq, test_meta_dt, test_meta_sym = build_sequences(\n",
        "    test_df, feature_cols, 'y_target', seq_len=SEQ_LEN\n",
        ")\n",
        "\n",
        "print(f\"Train sequences: {train_X_seq.shape}\")\n",
        "print(f\"Test sequences:  {test_X_seq.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9e55acb7",
      "metadata": {
        "id": "9e55acb7"
      },
      "outputs": [],
      "source": [
        "train_order = np.argsort(train_meta_dt)\n",
        "train_X_seq = train_X_seq[train_order]\n",
        "train_y_seq = train_y_seq[train_order]\n",
        "train_meta_dt = train_meta_dt[train_order]\n",
        "\n",
        "test_order = np.argsort(test_meta_dt)\n",
        "test_X_seq = test_X_seq[test_order]\n",
        "test_y_seq = test_y_seq[test_order]\n",
        "test_meta_dt = test_meta_dt[test_order]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "97970a31",
      "metadata": {
        "id": "97970a31"
      },
      "outputs": [],
      "source": [
        "y_scaler = StandardScaler()\n",
        "train_y_seq_raw = train_y_seq.copy()\n",
        "test_y_seq_raw = test_y_seq.copy()\n",
        "\n",
        "train_y_seq = y_scaler.fit_transform(train_y_seq.reshape(-1, 1)).astype(np.float32).ravel()\n",
        "test_y_seq = y_scaler.transform(test_y_seq.reshape(-1, 1)).astype(np.float32).ravel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d598dc5b",
      "metadata": {
        "id": "d598dc5b"
      },
      "source": [
        "## Prefix K-fold DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "165e9382",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "165e9382",
        "outputId": "8d678416-8379-4a74-9103-5c089acf13d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: train 1160 seq, val 1155 seq\n",
            "Fold 2: train 2315 seq, val 1155 seq\n",
            "Fold 3: train 3470 seq, val 1155 seq\n",
            "Fold 4: train 4625 seq, val 1155 seq\n",
            "Fold 5: train 5780 seq, val 1155 seq\n",
            "Fold 6: train 6935 seq, val 1155 seq\n",
            "Fold 7: train 8090 seq, val 1155 seq\n",
            "Fold 8: train 9245 seq, val 1155 seq\n",
            "Fold 9: train 10400 seq, val 1155 seq\n",
            "Fold 10: train 11555 seq, val 1155 seq\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "def create_prefix_folds(X_seq, y_seq, n_splits=10, batch_size=BATCH_SIZE):\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "    folds = []\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X_seq), start=1):\n",
        "        X_tr, y_tr = X_seq[train_idx], y_seq[train_idx]\n",
        "        X_va, y_va = X_seq[val_idx], y_seq[val_idx]\n",
        "        train_ds = TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(y_tr))\n",
        "        val_ds = TensorDataset(torch.from_numpy(X_va), torch.from_numpy(y_va))\n",
        "        folds.append((\n",
        "            DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
        "            DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "        ))\n",
        "        print(f\"Fold {fold_idx}: train {len(train_ds)} seq, val {len(val_ds)} seq\")\n",
        "    return folds\n",
        "\n",
        "prefix_folds = create_prefix_folds(train_X_seq, train_y_seq, n_splits=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec4e1c4",
      "metadata": {
        "id": "bec4e1c4"
      },
      "source": [
        "## Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f82760e5",
      "metadata": {
        "id": "f82760e5"
      },
      "outputs": [],
      "source": [
        "class ReturnTransformer(nn.Module):\n",
        "    def __init__(self, feature_dim, d_model=64, nhead=4, num_layers=2, ff_dim=128, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(feature_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            activation='gelu'\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.head = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        encoded = self.encoder(x)\n",
        "        return self.head(encoded[:, -1, :]).squeeze(-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e2e002c",
      "metadata": {
        "id": "0e2e002c"
      },
      "source": [
        "## Training utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e4e699d1",
      "metadata": {
        "id": "e4e699d1"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xb)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def eval_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            total_loss += loss.item() * len(xb)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def predict_batches(model, X_array, batch_size=512):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for start in range(0, len(X_array), batch_size):\n",
        "            batch = torch.from_numpy(X_array[start:start + batch_size]).to(DEVICE)\n",
        "            preds.append(model(batch).cpu().numpy())\n",
        "    return np.concatenate(preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b59bea10",
      "metadata": {
        "id": "b59bea10"
      },
      "outputs": [],
      "source": [
        "def evaluate_sharpe(model, loader, scaler):\n",
        "    model.eval()\n",
        "    preds_list, rets_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            preds = model(xb).cpu().numpy()\n",
        "            rets = yb.cpu().numpy()\n",
        "            preds_raw = scaler.inverse_transform(preds.reshape(-1, 1)).ravel()\n",
        "            rets_raw = scaler.inverse_transform(rets.reshape(-1, 1)).ravel()\n",
        "            preds_list.append(preds_raw)\n",
        "            rets_list.append(rets_raw)\n",
        "    preds = np.concatenate(preds_list)\n",
        "    rets = np.concatenate(rets_list)\n",
        "    return calculate_sharpe(pd.Series(preds * rets))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d52e09",
      "metadata": {
        "id": "e5d52e09"
      },
      "source": [
        "## Prefix CV training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "20e09f99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20e09f99",
        "outputId": "cc8273ad-c3fa-4d7a-e842-e193933478c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | Epoch 1 | train 0.821110 | val 0.361741 | val_SR -12.9365\n",
            "Fold 1 | Epoch 2 | train 0.653966 | val 0.250345 | val_SR 7.2762\n",
            "Fold 1 | Epoch 3 | train 0.613870 | val 0.243173 | val_SR 1.4122\n",
            "Fold 1 | Epoch 4 | train 0.594202 | val 0.215090 | val_SR 8.6539\n",
            "Fold 1 | Epoch 5 | train 0.574316 | val 0.214358 | val_SR 5.6651\n",
            "Fold 1 | Epoch 6 | train 0.572633 | val 0.237596 | val_SR 7.6779\n",
            "Fold 1 | Epoch 7 | train 0.563306 | val 0.218192 | val_SR 3.9724\n",
            "Fold 1 | Epoch 8 | train 0.563268 | val 0.216904 | val_SR 6.1427\n",
            "Stopping early on fold 1\n",
            "Fold 2 | Epoch 1 | train 0.652810 | val 0.537185 | val_SR -8.3652\n",
            "Fold 2 | Epoch 2 | train 0.435574 | val 0.480148 | val_SR 0.5324\n",
            "Fold 2 | Epoch 3 | train 0.406145 | val 0.479036 | val_SR 10.4968\n",
            "Fold 2 | Epoch 4 | train 0.401675 | val 0.474253 | val_SR 21.6939\n",
            "Fold 2 | Epoch 5 | train 0.397393 | val 0.480376 | val_SR -5.0319\n",
            "Fold 2 | Epoch 6 | train 0.391339 | val 0.483561 | val_SR 5.4250\n",
            "Fold 2 | Epoch 7 | train 0.394291 | val 0.484104 | val_SR 8.9879\n",
            "Stopping early on fold 2\n",
            "Fold 3 | Epoch 1 | train 0.592937 | val 0.880968 | val_SR -1.4703\n",
            "Fold 3 | Epoch 2 | train 0.437545 | val 0.871512 | val_SR -11.5346\n",
            "Fold 3 | Epoch 3 | train 0.429182 | val 0.878433 | val_SR -4.0210\n",
            "Fold 3 | Epoch 4 | train 0.422270 | val 0.869319 | val_SR -13.8572\n",
            "Fold 3 | Epoch 5 | train 0.415528 | val 0.871901 | val_SR -8.5728\n",
            "Fold 3 | Epoch 6 | train 0.411790 | val 0.880435 | val_SR -10.7878\n",
            "Fold 3 | Epoch 7 | train 0.408371 | val 0.886965 | val_SR -8.6876\n",
            "Stopping early on fold 3\n",
            "Fold 4 | Epoch 1 | train 0.618058 | val 0.325698 | val_SR 16.2476\n",
            "Fold 4 | Epoch 2 | train 0.543921 | val 0.326359 | val_SR 15.1525\n",
            "Fold 4 | Epoch 3 | train 0.535835 | val 0.329360 | val_SR 11.6041\n",
            "Fold 4 | Epoch 4 | train 0.534310 | val 0.325171 | val_SR 16.5624\n",
            "Fold 4 | Epoch 5 | train 0.535377 | val 0.327590 | val_SR 14.4865\n",
            "Fold 4 | Epoch 6 | train 0.542033 | val 0.327623 | val_SR 15.1674\n",
            "Fold 4 | Epoch 7 | train 0.525603 | val 0.332030 | val_SR 9.0214\n",
            "Stopping early on fold 4\n",
            "Fold 5 | Epoch 1 | train 0.611747 | val 0.462881 | val_SR -6.9441\n",
            "Fold 5 | Epoch 2 | train 0.504642 | val 0.463395 | val_SR -13.8014\n",
            "Fold 5 | Epoch 3 | train 0.495200 | val 0.463346 | val_SR -11.7062\n",
            "Fold 5 | Epoch 4 | train 0.495302 | val 0.458472 | val_SR -16.8690\n",
            "Fold 5 | Epoch 5 | train 0.489684 | val 0.461289 | val_SR -17.2990\n",
            "Fold 5 | Epoch 6 | train 0.486342 | val 0.465647 | val_SR -15.0272\n",
            "Fold 5 | Epoch 7 | train 0.486006 | val 0.468665 | val_SR -15.7427\n",
            "Stopping early on fold 5\n",
            "Fold 6 | Epoch 1 | train 0.593431 | val 0.128810 | val_SR 20.0094\n",
            "Fold 6 | Epoch 2 | train 0.501881 | val 0.128300 | val_SR 13.2062\n",
            "Fold 6 | Epoch 3 | train 0.493015 | val 0.129267 | val_SR 21.0378\n",
            "Fold 6 | Epoch 4 | train 0.490534 | val 0.126270 | val_SR 20.6796\n",
            "Fold 6 | Epoch 5 | train 0.489452 | val 0.126999 | val_SR 18.0516\n",
            "Fold 6 | Epoch 6 | train 0.483633 | val 0.128977 | val_SR 12.8327\n",
            "Fold 6 | Epoch 7 | train 0.483221 | val 0.125837 | val_SR 20.2044\n",
            "Fold 6 | Epoch 8 | train 0.484309 | val 0.127491 | val_SR 20.6249\n",
            "Fold 6 | Epoch 9 | train 0.484197 | val 0.127964 | val_SR 17.5551\n",
            "Fold 6 | Epoch 10 | train 0.479944 | val 0.138527 | val_SR 8.0078\n",
            "Stopping early on fold 6\n",
            "Fold 7 | Epoch 1 | train 0.469575 | val 1.872306 | val_SR -6.3764\n",
            "Fold 7 | Epoch 2 | train 0.438435 | val 1.869916 | val_SR 6.7081\n",
            "Fold 7 | Epoch 3 | train 0.435064 | val 1.868151 | val_SR 1.3550\n",
            "Fold 7 | Epoch 4 | train 0.438660 | val 1.880312 | val_SR -7.4690\n",
            "Fold 7 | Epoch 5 | train 0.436161 | val 1.870243 | val_SR -2.8897\n",
            "Fold 7 | Epoch 6 | train 0.433584 | val 1.869641 | val_SR -4.9788\n",
            "Stopping early on fold 7\n",
            "Fold 8 | Epoch 1 | train 0.695126 | val 1.212723 | val_SR 10.1590\n",
            "Fold 8 | Epoch 2 | train 0.620670 | val 1.217013 | val_SR 11.8789\n",
            "Fold 8 | Epoch 3 | train 0.618810 | val 1.215118 | val_SR 0.7676\n",
            "Fold 8 | Epoch 4 | train 0.615191 | val 1.229968 | val_SR -6.5690\n",
            "Stopping early on fold 8\n",
            "Fold 9 | Epoch 1 | train 0.725531 | val 3.492810 | val_SR 6.4813\n",
            "Fold 9 | Epoch 2 | train 0.691165 | val 3.491865 | val_SR -11.8929\n",
            "Fold 9 | Epoch 3 | train 0.682393 | val 3.490117 | val_SR 4.9400\n",
            "Fold 9 | Epoch 4 | train 0.681047 | val 3.487878 | val_SR 3.6952\n",
            "Fold 9 | Epoch 5 | train 0.681741 | val 3.496312 | val_SR -11.7028\n",
            "Fold 9 | Epoch 6 | train 0.677820 | val 3.504466 | val_SR -10.5586\n",
            "Fold 9 | Epoch 7 | train 0.680912 | val 3.492769 | val_SR -12.0579\n",
            "Stopping early on fold 9\n",
            "Fold 10 | Epoch 1 | train 1.087468 | val 1.425109 | val_SR 9.4770\n",
            "Fold 10 | Epoch 2 | train 0.971328 | val 1.423443 | val_SR 10.6185\n",
            "Fold 10 | Epoch 3 | train 0.971376 | val 1.417837 | val_SR -7.0699\n",
            "Fold 10 | Epoch 4 | train 0.962793 | val 1.416945 | val_SR -4.5820\n",
            "Fold 10 | Epoch 5 | train 0.963235 | val 1.420493 | val_SR -10.5887\n",
            "Fold 10 | Epoch 6 | train 0.961511 | val 1.416319 | val_SR -2.4327\n",
            "Fold 10 | Epoch 7 | train 0.960496 | val 1.422856 | val_SR -12.9502\n",
            "Fold 10 | Epoch 8 | train 0.961007 | val 1.425738 | val_SR -14.6515\n",
            "Fold 10 | Epoch 9 | train 0.959089 | val 1.427680 | val_SR -12.4544\n",
            "Stopping early on fold 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'fold': 1,\n",
              "  'best_val_mse': 0.21435808161378422,\n",
              "  'best_val_sharpe': np.float64(5.665060368494481)},\n",
              " {'fold': 2,\n",
              "  'best_val_mse': 0.4742531318620686,\n",
              "  'best_val_sharpe': np.float64(21.693905478080694)},\n",
              " {'fold': 3,\n",
              "  'best_val_mse': 0.8693194981777307,\n",
              "  'best_val_sharpe': np.float64(-13.857241924483475)},\n",
              " {'fold': 4,\n",
              "  'best_val_mse': 0.32517106115043937,\n",
              "  'best_val_sharpe': np.float64(16.562425174177765)},\n",
              " {'fold': 5,\n",
              "  'best_val_mse': 0.4584722115234895,\n",
              "  'best_val_sharpe': np.float64(-16.8689710876445)},\n",
              " {'fold': 6,\n",
              "  'best_val_mse': 0.1258370710948071,\n",
              "  'best_val_sharpe': np.float64(20.204365899362813)},\n",
              " {'fold': 7,\n",
              "  'best_val_mse': 1.8681512706207506,\n",
              "  'best_val_sharpe': np.float64(1.354979909058905)},\n",
              " {'fold': 8,\n",
              "  'best_val_mse': 1.2127228436789987,\n",
              "  'best_val_sharpe': np.float64(10.159013603135019)},\n",
              " {'fold': 9,\n",
              "  'best_val_mse': 3.4878782105910315,\n",
              "  'best_val_sharpe': np.float64(3.6951565440633796)},\n",
              " {'fold': 10,\n",
              "  'best_val_mse': 1.4163185643943357,\n",
              "  'best_val_sharpe': np.float64(-2.4326724300091245)}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "def fit_with_prefix_cv(folds, feature_dim, epochs=15, lr=1e-3, weight_decay=1e-4, patience=3):\n",
        "    histories = []\n",
        "    best_states = []\n",
        "    for fold_idx, (train_loader, val_loader) in enumerate(folds, start=1):\n",
        "        model = ReturnTransformer(feature_dim).to(DEVICE)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        criterion = nn.MSELoss()\n",
        "        best_val = math.inf\n",
        "        best_sharpe = -math.inf\n",
        "        best_state = None\n",
        "        patience_ctr = 0\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "            val_loss = eval_epoch(model, val_loader, criterion)\n",
        "            val_sharpe = evaluate_sharpe(model, val_loader, y_scaler)\n",
        "            improved = False\n",
        "            if val_loss < best_val - 1e-6:\n",
        "                improved = True\n",
        "            elif abs(val_loss - best_val) <= 1e-6 and val_sharpe > best_sharpe + 1e-3:\n",
        "                improved = True\n",
        "            if improved:\n",
        "                best_val = val_loss\n",
        "                best_sharpe = val_sharpe\n",
        "                best_state = copy.deepcopy(model.state_dict())\n",
        "                patience_ctr = 0\n",
        "            else:\n",
        "                patience_ctr += 1\n",
        "            print(f\"Fold {fold_idx} | Epoch {epoch} | train {train_loss:.6f} | val {val_loss:.6f} | val_SR {val_sharpe:.4f}\")\n",
        "            if patience_ctr >= patience:\n",
        "                print(f\"Stopping early on fold {fold_idx}\")\n",
        "                break\n",
        "        histories.append({'fold': fold_idx,\n",
        "                          'best_val_mse': best_val,\n",
        "                          'best_val_sharpe': best_sharpe})\n",
        "        best_states.append(best_state)\n",
        "    return histories, best_states\n",
        "\n",
        "cv_histories, cv_states = fit_with_prefix_cv(\n",
        "    prefix_folds,\n",
        "    feature_dim=len(feature_cols),\n",
        "    epochs=12,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    patience=3,\n",
        ")\n",
        "cv_histories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f36e35d",
      "metadata": {
        "id": "4f36e35d"
      },
      "source": [
        "## Final training on full training window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4771189a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4771189a",
        "outputId": "b42f6cff-fa0d-47de-e011-7354b0c07628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | train 1.000361 | val 1.334176 | val_SR -16.5330\n",
            "Epoch 2 | train 0.978309 | val 1.335929 | val_SR -17.1215\n",
            "Epoch 3 | train 0.970826 | val 1.336135 | val_SR -15.1484\n",
            "Early stopping triggered (loss plateau / Sharpe deterioration).\n",
            "Best val MSE: 1.334176, best val Sharpe: -16.5330\n"
          ]
        }
      ],
      "source": [
        "VALID_SPLIT = int(len(train_X_seq) * 0.9)\n",
        "full_train_ds = TensorDataset(\n",
        "    torch.from_numpy(train_X_seq[:VALID_SPLIT]),\n",
        "    torch.from_numpy(train_y_seq[:VALID_SPLIT])\n",
        ")\n",
        "full_val_ds = TensorDataset(\n",
        "    torch.from_numpy(train_X_seq[VALID_SPLIT:]),\n",
        "    torch.from_numpy(train_y_seq[VALID_SPLIT:])\n",
        ")\n",
        "full_train_loader = DataLoader(full_train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "full_val_loader = DataLoader(full_val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "final_model = ReturnTransformer(len(feature_cols)).to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(final_model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "best_state = None\n",
        "best_val = math.inf\n",
        "best_sharpe = -math.inf\n",
        "patience = 4\n",
        "patience_ctr = 0\n",
        "divergent_ctr = 0\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    train_loss = train_epoch(final_model, full_train_loader, optimizer, criterion)\n",
        "    val_loss = eval_epoch(final_model, full_val_loader, criterion)\n",
        "    val_sharpe = evaluate_sharpe(final_model, full_val_loader, y_scaler)\n",
        "\n",
        "    improved = False\n",
        "    if val_loss < best_val - 1e-6:\n",
        "        improved = True\n",
        "    elif abs(val_loss - best_val) <= 1e-6 and val_sharpe > best_sharpe + 1e-3:\n",
        "        improved = True\n",
        "\n",
        "    if improved:\n",
        "        best_val = val_loss\n",
        "        best_sharpe = val_sharpe\n",
        "        best_state = copy.deepcopy(final_model.state_dict())\n",
        "        patience_ctr = 0\n",
        "        divergent_ctr = 0\n",
        "    else:\n",
        "        patience_ctr += 1\n",
        "        if val_sharpe < 0:\n",
        "            divergent_ctr += 1\n",
        "\n",
        "    print(f\"Epoch {epoch} | train {train_loss:.6f} | val {val_loss:.6f} | val_SR {val_sharpe:.4f}\")\n",
        "\n",
        "    if patience_ctr >= patience or divergent_ctr >= 2:\n",
        "        print(\"Early stopping triggered (loss plateau / Sharpe deterioration).\")\n",
        "        break\n",
        "\n",
        "final_model.load_state_dict(best_state)\n",
        "print(f\"Best val MSE: {best_val:.6f}, best val Sharpe: {best_sharpe:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e69b96e",
      "metadata": {
        "id": "8e69b96e"
      },
      "source": [
        "## Sharpe evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "57299cbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57299cbd",
        "outputId": "81d85fe6-c5b8-4d52-e763-9b0e2bb9349c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sharpe: 6.402199\n",
            "Test Sharpe:  3.562124\n"
          ]
        }
      ],
      "source": [
        "train_preds = predict_batches(final_model, train_X_seq)\n",
        "train_preds_raw = y_scaler.inverse_transform(train_preds.reshape(-1, 1)).ravel()\n",
        "train_pnl = pd.Series(train_preds_raw * train_y_seq_raw)\n",
        "train_sharpe = calculate_sharpe(train_pnl)\n",
        "\n",
        "test_preds = predict_batches(final_model, test_X_seq)\n",
        "test_preds_raw = y_scaler.inverse_transform(test_preds.reshape(-1, 1)).ravel()\n",
        "test_pnl = pd.Series(test_preds_raw * test_y_seq_raw)\n",
        "test_sharpe = calculate_sharpe(test_pnl)\n",
        "\n",
        "print(f\"Train Sharpe: {train_sharpe:.6f}\")\n",
        "print(f\"Test Sharpe:  {test_sharpe:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6297dba",
      "metadata": {
        "id": "d6297dba"
      },
      "source": [
        "## Rolling 30-minute backtest (optional heavy cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2a83a386",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "175e0fe3625247d98ed9d7664f3d2784",
            "7c4eea15d9f84d1da54860cac470d8f3",
            "e2ca3e3a716c4d7fae70532a853c477a",
            "658634f2f29d478fad2ddc5f1efe01fd",
            "4e77b632b7e3437085a96731d2e349d3",
            "0a3a8aee43284af7b50208c9716f6b95",
            "c49299ba2d16497ea5e81bcc94b0bd3b",
            "dec19ba997b64d488cb209a6ccb9c0e8",
            "6a08fe58d30a4aec893af282f30fb7af",
            "9cd20c0e753048b89f4d0e92b199e544",
            "addae893e63d4079a80d0529bd2c31f4"
          ]
        },
        "id": "2a83a386",
        "outputId": "d30a3909-c56d-4a40-816f-d51ddf1fb543"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Rolling backtest:   0%|          | 0/6371 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "175e0fe3625247d98ed9d7664f3d2784"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             datetime symbol  predicted_log_return  actual_log_return  \\\n",
            "0 2024-08-15 13:40:00   AMAT              0.000154           0.002123   \n",
            "1 2024-08-15 13:41:00   AMAT              0.000481           0.000448   \n",
            "2 2024-08-15 13:42:00   AMAT             -0.000249          -0.000848   \n",
            "3 2024-08-15 13:43:00   AMAT              0.000362          -0.000330   \n",
            "4 2024-08-15 13:44:00   AMAT              0.000298           0.001414   \n",
            "\n",
            "   weight_relative  weight_sign  \n",
            "0              1.0          1.0  \n",
            "1              1.0          1.0  \n",
            "2              0.0         -1.0  \n",
            "3              1.0          1.0  \n",
            "4              1.0          1.0  \n",
            "Backtest rows: 4682\n"
          ]
        }
      ],
      "source": [
        "ROLLING_WINDOW_MINUTES = 60\n",
        "MIN_SEQ_PER_WINDOW = 20\n",
        "\n",
        "\n",
        "def build_window_sequences(window_df, feature_cols, seq_len=SEQ_LEN):\n",
        "    X_seq, y_seq = [], []\n",
        "    for symbol, group in window_df.groupby('symbol'):\n",
        "        group = group.sort_values('datetime')\n",
        "        if len(group) < seq_len + 1:\n",
        "            continue\n",
        "        feats = group[feature_cols].values\n",
        "        target = group['y_target'].values\n",
        "        for i in range(len(group) - seq_len):\n",
        "            X_seq.append(feats[i:i+seq_len])\n",
        "            y_seq.append(target[i+seq_len])\n",
        "    if not X_seq:\n",
        "        return None, None\n",
        "    return np.array(X_seq, dtype=np.float32), np.array(y_seq, dtype=np.float32)\n",
        "\n",
        "backtest_results = []\n",
        "unique_test_minutes = np.sort(test_df['datetime'].unique())\n",
        "\n",
        "for current_dt in tqdm(unique_test_minutes, desc='Rolling backtest'):\n",
        "    start_dt = current_dt - pd.Timedelta(minutes=ROLLING_WINDOW_MINUTES)\n",
        "    window_df = df_processed[(df_processed['datetime'] >= start_dt) & (df_processed['datetime'] < current_dt)]\n",
        "    X_tr, y_tr = build_window_sequences(window_df, feature_cols, seq_len=SEQ_LEN)\n",
        "    if X_tr is None or len(X_tr) < MIN_SEQ_PER_WINDOW:\n",
        "        continue\n",
        "    window_scaler = StandardScaler()\n",
        "    y_tr_scaled = window_scaler.fit_transform(y_tr.reshape(-1, 1)).astype(np.float32).ravel()\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(y_tr_scaled)),\n",
        "        batch_size=128,\n",
        "        shuffle=True\n",
        "    )\n",
        "    temp_model = ReturnTransformer(len(feature_cols)).to(DEVICE)\n",
        "    optimizer = torch.optim.AdamW(temp_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    criterion = nn.MSELoss()\n",
        "    for _ in range(3):\n",
        "        train_epoch(temp_model, train_loader, optimizer, criterion)\n",
        "\n",
        "    # Build prediction sequences ending at current_dt for each symbol\n",
        "    pred_rows = df_processed[df_processed['datetime'] == current_dt]\n",
        "    symbol_preds = []\n",
        "    combined = pd.concat([window_df, pred_rows], ignore_index=True)\n",
        "    for symbol, group in combined.groupby('symbol'):\n",
        "        group = group.sort_values('datetime')\n",
        "        if group['datetime'].iloc[-1] != current_dt:\n",
        "            continue\n",
        "        if len(group) < SEQ_LEN:\n",
        "            continue\n",
        "        seq = group[feature_cols].values[-SEQ_LEN:]\n",
        "        symbol_preds.append((symbol, seq))\n",
        "\n",
        "    if not symbol_preds:\n",
        "        continue\n",
        "\n",
        "    batch = np.stack([seq for _, seq in symbol_preds]).astype(np.float32)\n",
        "    batch = torch.from_numpy(batch).to(DEVICE)\n",
        "    temp_model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds_scaled = temp_model(batch).cpu().numpy()\n",
        "    preds_raw = window_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "    actuals = df_processed[df_processed['datetime'] == current_dt][['symbol', 'y_target']]\n",
        "    actual_map = dict(zip(actuals['symbol'], actuals['y_target']))\n",
        "    for (symbol, _), pred in zip(symbol_preds, preds_raw):\n",
        "        if symbol not in actual_map:\n",
        "            continue\n",
        "        backtest_results.append({\n",
        "            'datetime': current_dt,\n",
        "            'symbol': symbol,\n",
        "            'predicted_log_return': pred,\n",
        "            'actual_log_return': actual_map[symbol]\n",
        "        })\n",
        "\n",
        "backtest_df = pd.DataFrame(backtest_results)\n",
        "if not backtest_df.empty:\n",
        "    backtest_df['positive_prediction'] = backtest_df['predicted_log_return'].clip(lower=0)\n",
        "    minute_sum = backtest_df.groupby('datetime')['positive_prediction'].transform('sum')\n",
        "    backtest_df['weight_relative'] = np.where(minute_sum == 0, 0.0, backtest_df['positive_prediction'] / minute_sum)\n",
        "    backtest_df.drop(columns=['positive_prediction'], inplace=True)\n",
        "    backtest_df['weight_sign'] = np.sign(backtest_df['predicted_log_return'])\n",
        "    print(backtest_df.head())\n",
        "    print(f\"Backtest rows: {len(backtest_df)}\")\n",
        "else:\n",
        "    print(\"Backtest skipped due to insufficient sequences\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backtest_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "ucycjNDcbIOI",
        "outputId": "715c7de9-6cf5-4205-906a-816bec3b52d7"
      },
      "id": "ucycjNDcbIOI",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             datetime symbol  predicted_log_return  actual_log_return  \\\n",
              "0 2024-08-15 13:40:00   AMAT              0.000154           0.002123   \n",
              "1 2024-08-15 13:41:00   AMAT              0.000481           0.000448   \n",
              "2 2024-08-15 13:42:00   AMAT             -0.000249          -0.000848   \n",
              "3 2024-08-15 13:43:00   AMAT              0.000362          -0.000330   \n",
              "4 2024-08-15 13:44:00   AMAT              0.000298           0.001414   \n",
              "\n",
              "   weight_relative  weight_sign  \n",
              "0              1.0          1.0  \n",
              "1              1.0          1.0  \n",
              "2              0.0         -1.0  \n",
              "3              1.0          1.0  \n",
              "4              1.0          1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a12d85a9-87d9-4d80-bc0c-9b0e3900aa53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>symbol</th>\n",
              "      <th>predicted_log_return</th>\n",
              "      <th>actual_log_return</th>\n",
              "      <th>weight_relative</th>\n",
              "      <th>weight_sign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-08-15 13:40:00</td>\n",
              "      <td>AMAT</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.002123</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-08-15 13:41:00</td>\n",
              "      <td>AMAT</td>\n",
              "      <td>0.000481</td>\n",
              "      <td>0.000448</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-08-15 13:42:00</td>\n",
              "      <td>AMAT</td>\n",
              "      <td>-0.000249</td>\n",
              "      <td>-0.000848</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-08-15 13:43:00</td>\n",
              "      <td>AMAT</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>-0.000330</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-08-15 13:44:00</td>\n",
              "      <td>AMAT</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>0.001414</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a12d85a9-87d9-4d80-bc0c-9b0e3900aa53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a12d85a9-87d9-4d80-bc0c-9b0e3900aa53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a12d85a9-87d9-4d80-bc0c-9b0e3900aa53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-97cd8990-97d8-4584-b78f-628497284b8f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97cd8990-97d8-4584-b78f-628497284b8f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-97cd8990-97d8-4584-b78f-628497284b8f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "backtest_df",
              "summary": "{\n  \"name\": \"backtest_df\",\n  \"rows\": 4682,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-08-15 13:40:00\",\n        \"max\": \"2024-10-07 14:41:00\",\n        \"num_unique_values\": 4682,\n        \"samples\": [\n          \"2024-08-20 14:31:00\",\n          \"2024-09-18 15:02:00\",\n          \"2024-09-09 15:01:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AMAT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_log_return\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4681,\n        \"samples\": [\n          0.00039165106136351824\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"actual_log_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0021949020064869628,\n        \"min\": -0.06479193590287124,\n        \"max\": 0.059069106696942875,\n        \"num_unique_values\": 4556,\n        \"samples\": [\n          -9.657636783799717e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_relative\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_sign\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pnl_series = backtest_df[\"weight_sign\"] * backtest_df[\"actual_log_return\"]\n",
        "#  long-only backtest_df[\"weight_relative\"] * actual_log_return\n",
        "\n",
        "raw_sharpe = pnl_series.mean() / pnl_series.std()\n",
        "\n",
        "# \n",
        "minutes_per_day = 390        # \n",
        "trading_days_per_year = 252\n",
        "periods_per_year = minutes_per_day * trading_days_per_year\n",
        "\n",
        "annual_sharpe = raw_sharpe * np.sqrt(periods_per_year)\n",
        "print(raw_sharpe, annual_sharpe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fExBk7pOeKNT",
        "outputId": "172d967a-c286-465a-c868-33bcf0609e86"
      },
      "id": "fExBk7pOeKNT",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.01704421911954488 -5.3433015301615185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save backtest results\n",
        "BACKTEST_PATH = Path('transformer_backtest_results.csv')\n",
        "backtest_df.to_csv(BACKTEST_PATH, index=False)\n",
        "print(f\"Backtest results saved to {BACKTEST_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKsxiCvWeaCP",
        "outputId": "7705e803-0bd8-4f1a-bfc3-7c9e00cf196c"
      },
      "id": "VKsxiCvWeaCP",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backtest results saved to transformer_backtest_results.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "175e0fe3625247d98ed9d7664f3d2784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c4eea15d9f84d1da54860cac470d8f3",
              "IPY_MODEL_e2ca3e3a716c4d7fae70532a853c477a",
              "IPY_MODEL_658634f2f29d478fad2ddc5f1efe01fd"
            ],
            "layout": "IPY_MODEL_4e77b632b7e3437085a96731d2e349d3"
          }
        },
        "7c4eea15d9f84d1da54860cac470d8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a3a8aee43284af7b50208c9716f6b95",
            "placeholder": "",
            "style": "IPY_MODEL_c49299ba2d16497ea5e81bcc94b0bd3b",
            "value": "Rollingbacktest:100%"
          }
        },
        "e2ca3e3a716c4d7fae70532a853c477a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec19ba997b64d488cb209a6ccb9c0e8",
            "max": 6371,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a08fe58d30a4aec893af282f30fb7af",
            "value": 6371
          }
        },
        "658634f2f29d478fad2ddc5f1efe01fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cd20c0e753048b89f4d0e92b199e544",
            "placeholder": "",
            "style": "IPY_MODEL_addae893e63d4079a80d0529bd2c31f4",
            "value": "6371/6371[03:00&lt;00:00,34.94it/s]"
          }
        },
        "4e77b632b7e3437085a96731d2e349d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3a8aee43284af7b50208c9716f6b95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c49299ba2d16497ea5e81bcc94b0bd3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dec19ba997b64d488cb209a6ccb9c0e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a08fe58d30a4aec893af282f30fb7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cd20c0e753048b89f4d0e92b199e544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "addae893e63d4079a80d0529bd2c31f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}