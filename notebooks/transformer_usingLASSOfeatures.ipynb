{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee87b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80434c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_FEATURES_PATH = \"../data/selected_features.json\"\n",
    "\n",
    "if Path(SELECTED_FEATURES_PATH).exists():\n",
    "    with open(SELECTED_FEATURES_PATH, \"r\") as f:\n",
    "        SELECTED_FEATURES = json.load(f)\n",
    "    print(f\"Loaded {len(SELECTED_FEATURES)} fixed features.\")\n",
    "else:\n",
    "    all_cols = sorted(X.columns.tolist())\n",
    "    print(all_cols)  # 你手动删除滞后列后再写入\n",
    "    raise SystemExit(\"请根据打印的列手动编辑，并保存到 JSON\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e3c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sharpe(pnl_series, periods_per_year=390*252):\n",
    "    std = pnl_series.std()\n",
    "    if std == 0:\n",
    "        return 0.0\n",
    "    raw = pnl_series.mean() / std\n",
    "    return raw * np.sqrt(periods_per_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1630f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f9fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/final_df.csv' \n",
    "try:\n",
    "    df_ori = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"*** ERROR: Cannot find {file_path} ***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0cb608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dropped 12 unusal/NaN y value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>f_minsin</th>\n",
       "      <th>f_mincos</th>\n",
       "      <th>...</th>\n",
       "      <th>split_nonpos_flag</th>\n",
       "      <th>shares_out</th>\n",
       "      <th>log_shares_out</th>\n",
       "      <th>eps_surp_pct_final</th>\n",
       "      <th>div_amount</th>\n",
       "      <th>log_shares_out_iqr_outlier</th>\n",
       "      <th>eps_estimate_rz_8</th>\n",
       "      <th>eps_actual</th>\n",
       "      <th>lret_1m</th>\n",
       "      <th>y_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.220697</td>\n",
       "      <td>-0.975342</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>830897024</td>\n",
       "      <td>20.538016</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.220697</td>\n",
       "      <td>-0.975342</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1616140032</td>\n",
       "      <td>21.203306</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.220697</td>\n",
       "      <td>-0.975342</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>465308000</td>\n",
       "      <td>19.958210</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.000721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>MU</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.220697</td>\n",
       "      <td>-0.975342</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1107369984</td>\n",
       "      <td>20.825254</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>-0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.220697</td>\n",
       "      <td>-0.975342</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2500000000</td>\n",
       "      <td>21.639557</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.000769</td>\n",
       "      <td>-0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324883</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.861629</td>\n",
       "      <td>-0.507538</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>796642427</td>\n",
       "      <td>20.495916</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324884</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.861629</td>\n",
       "      <td>-0.507538</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1633284837</td>\n",
       "      <td>21.213859</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324885</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.861629</td>\n",
       "      <td>-0.507538</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4722365022</td>\n",
       "      <td>22.275576</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324886</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>MU</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.861629</td>\n",
       "      <td>-0.507538</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1122466035</td>\n",
       "      <td>20.838794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>-0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324887</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.861629</td>\n",
       "      <td>-0.507538</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24347000000</td>\n",
       "      <td>23.915674</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.000025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324888 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime symbol  dow_0  dow_1  dow_2  dow_3  dow_4  dow_5  \\\n",
       "0      2024-04-30 12:51:00   AMAT      0      1      0      0      0      0   \n",
       "1      2024-04-30 12:51:00    AMD      0      1      0      0      0      0   \n",
       "2      2024-04-30 12:51:00   AVGO      0      1      0      0      0      0   \n",
       "3      2024-04-30 12:51:00     MU      0      1      0      0      0      0   \n",
       "4      2024-04-30 12:51:00   NVDA      0      1      0      0      0      0   \n",
       "...                    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "324883 2025-10-28 15:58:00   AMAT      0      1      0      0      0      0   \n",
       "324884 2025-10-28 15:58:00    AMD      0      1      0      0      0      0   \n",
       "324885 2025-10-28 15:58:00   AVGO      0      1      0      0      0      0   \n",
       "324886 2025-10-28 15:58:00     MU      0      1      0      0      0      0   \n",
       "324887 2025-10-28 15:58:00   NVDA      0      1      0      0      0      0   \n",
       "\n",
       "        f_minsin  f_mincos  ...  split_nonpos_flag   shares_out  \\\n",
       "0      -0.220697 -0.975342  ...                  1    830897024   \n",
       "1      -0.220697 -0.975342  ...                  1   1616140032   \n",
       "2      -0.220697 -0.975342  ...                  1    465308000   \n",
       "3      -0.220697 -0.975342  ...                  1   1107369984   \n",
       "4      -0.220697 -0.975342  ...                  1   2500000000   \n",
       "...          ...       ...  ...                ...          ...   \n",
       "324883 -0.861629 -0.507538  ...                  1    796642427   \n",
       "324884 -0.861629 -0.507538  ...                  1   1633284837   \n",
       "324885 -0.861629 -0.507538  ...                  1   4722365022   \n",
       "324886 -0.861629 -0.507538  ...                  1   1122466035   \n",
       "324887 -0.861629 -0.507538  ...                  1  24347000000   \n",
       "\n",
       "        log_shares_out  eps_surp_pct_final  div_amount  \\\n",
       "0            20.538016                0.00         0.0   \n",
       "1            21.203306                2.04         0.0   \n",
       "2            19.958210                0.00         0.0   \n",
       "3            20.825254                0.00         0.0   \n",
       "4            21.639557                0.00         0.0   \n",
       "...                ...                 ...         ...   \n",
       "324883       20.495916                0.00         0.0   \n",
       "324884       21.213859                0.00         0.0   \n",
       "324885       22.275576                0.00         0.0   \n",
       "324886       20.838794                0.00         0.0   \n",
       "324887       23.915674                0.00         0.0   \n",
       "\n",
       "        log_shares_out_iqr_outlier  eps_estimate_rz_8  eps_actual   lret_1m  \\\n",
       "0                                0                0.0        0.00 -0.000199   \n",
       "1                                0                0.0        0.62  0.000314   \n",
       "2                                0                0.0        0.00 -0.000334   \n",
       "3                                0                0.0        0.00  0.000698   \n",
       "4                                0                0.0        0.00 -0.000769   \n",
       "...                            ...                ...         ...       ...   \n",
       "324883                           0                0.0        0.00 -0.000461   \n",
       "324884                           0                0.0        0.00 -0.000698   \n",
       "324885                           0                0.0        0.00  0.000161   \n",
       "324886                           0                0.0        0.00  0.000270   \n",
       "324887                           0                0.0        0.00  0.000348   \n",
       "\n",
       "        y_target  \n",
       "0      -0.000100  \n",
       "1      -0.000126  \n",
       "2       0.000721  \n",
       "3      -0.000698  \n",
       "4      -0.000907  \n",
       "...          ...  \n",
       "324883 -0.000132  \n",
       "324884 -0.001316  \n",
       "324885  0.000375  \n",
       "324886 -0.000135  \n",
       "324887 -0.000025  \n",
       "\n",
       "[324888 rows x 191 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df_ori.copy()\n",
    "\n",
    "# Sort by symbol and datetime\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.sort_values(by=['symbol', 'datetime'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['lret_1m'] = df.groupby('symbol')['close'].transform(lambda s: np.log(s).diff())\n",
    "df['y_target'] = df.groupby('symbol')['lret_1m'].shift(-1)\n",
    "\n",
    "initial_rows = len(df)\n",
    "df = df[(df['y_target'].abs() <= 0.2)]\n",
    "df = df.dropna(subset=['y_target', 'lret_1m'])\n",
    "\n",
    "print(f\"(Dropped {initial_rows - len(df)} unusal/NaN y value)\")\n",
    "\n",
    "# --- Re-sort by datatime, symbol ---\n",
    "df = df.sort_values(by=['datetime', 'symbol'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed113a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>fz_lret_1_rolling</th>\n",
       "      <th>lret_1m</th>\n",
       "      <th>y_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>-0.194539</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>AMD</td>\n",
       "      <td>0.722399</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>-0.248127</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.000721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>MU</td>\n",
       "      <td>0.793029</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>-0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-30 12:51:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>-1.007944</td>\n",
       "      <td>-0.000769</td>\n",
       "      <td>-0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324883</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>-0.714656</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324884</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>AMD</td>\n",
       "      <td>-0.811072</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324885</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>-0.057482</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324886</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>MU</td>\n",
       "      <td>0.281664</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>-0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324887</th>\n",
       "      <td>2025-10-28 15:58:00</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.116461</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.000025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324888 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime symbol  fz_lret_1_rolling   lret_1m  y_target\n",
       "0      2024-04-30 12:51:00   AMAT          -0.194539 -0.000199 -0.000100\n",
       "1      2024-04-30 12:51:00    AMD           0.722399  0.000314 -0.000126\n",
       "2      2024-04-30 12:51:00   AVGO          -0.248127 -0.000334  0.000721\n",
       "3      2024-04-30 12:51:00     MU           0.793029  0.000698 -0.000698\n",
       "4      2024-04-30 12:51:00   NVDA          -1.007944 -0.000769 -0.000907\n",
       "...                    ...    ...                ...       ...       ...\n",
       "324883 2025-10-28 15:58:00   AMAT          -0.714656 -0.000461 -0.000132\n",
       "324884 2025-10-28 15:58:00    AMD          -0.811072 -0.000698 -0.001316\n",
       "324885 2025-10-28 15:58:00   AVGO          -0.057482  0.000161  0.000375\n",
       "324886 2025-10-28 15:58:00     MU           0.281664  0.000270 -0.000135\n",
       "324887 2025-10-28 15:58:00   NVDA           0.116461  0.000348 -0.000025\n",
       "\n",
       "[324888 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[[\"datetime\", \"symbol\", 'fz_lret_1_rolling', \"lret_1m\", \"y_target\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8bc0c",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67425670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X original shape: (324888, 184)\n",
      "--- Dropping 37 bad cols ---\n",
      "  - cnt_15m_rs\n",
      "  - cnt_30m_rs\n",
      "  - cnt_5m_rs\n",
      "  - cnt_60m_rs\n",
      "  - div_negative_flag\n",
      "  - dow_5\n",
      "  - dow_6\n",
      "  - eps_actual_iqr_outlier\n",
      "  - eps_estimate_iqr_outlier\n",
      "  - fz_vol_ratio_60\n",
      "  - mins_since_last_news_rs\n",
      "  - morning_n_rs\n",
      "  - morning_source_div_rs\n",
      "  - morning_tone_mean_rs\n",
      "  - morning_tone_sum_rs\n",
      "  - n_news_ewm_hl15_is_zero\n",
      "  - n_news_ewm_hl15_rs\n",
      "  - n_news_ewm_hl5_is_zero\n",
      "  - n_news_ewm_hl5_rs\n",
      "  - n_news_rs\n",
      "  - n_pos_raw_rs\n",
      "  - overnight_n_rs\n",
      "  - overnight_source_div_rs\n",
      "  - overnight_tone_mean_rs\n",
      "  - overnight_tone_sum_rs\n",
      "  - shares_out\n",
      "  - shares_out_ffill\n",
      "  - shares_out_nonpos_flag\n",
      "  - split_flag\n",
      "  - surprise_tone_mean_rs\n",
      "  - tone_ewm15_rs\n",
      "  - tone_ewm30_rs\n",
      "  - tone_mean_delta_rs\n",
      "  - tone_mean_ewm_hl15_rs\n",
      "  - tone_mean_rs\n",
      "  - tone_sum_rs\n",
      "  - volume\n",
      "\n",
      "--- X cleaned ---\n",
      "X (cleaned) shape: (324888, 147)\n"
     ]
    }
   ],
   "source": [
    "y = df['y_target']\n",
    "X = df.drop(columns=[\n",
    "    'y_target', 'lret_1m', 'datetime', 'symbol',  \n",
    "    'year', 'month', 'day', 'minute', 'minute_of_day'\n",
    "], errors='ignore')\n",
    "\n",
    "print(f\"X original shape: {X.shape}\")\n",
    "\n",
    "# --- Find bad Cols with wrong data ---\n",
    "desc = X.describe(percentiles=[0.99]).T\n",
    "bad_cols = []\n",
    "\n",
    "# std > 1000\n",
    "bad_cols += desc.index[desc['std'] > 1e3].tolist()\n",
    "# 99% > 1000\n",
    "bad_cols += desc.index[desc['99%'].abs() > 1e3].tolist()\n",
    "# Max > 1,000,000\n",
    "bad_cols += desc.index[desc['max'].abs() > 1e6].tolist()\n",
    "# Constant columns\n",
    "bad_cols += desc.index[desc['std'] == 0].tolist()\n",
    "\n",
    "bad_cols_set = sorted(set(bad_cols))\n",
    "print(f\"--- Dropping {len(bad_cols_set)} bad cols ---\")\n",
    "for col in bad_cols_set:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# --- Drop bad cols ---\n",
    "X_cleaned = X.drop(columns=bad_cols_set)\n",
    "\n",
    "print(f\"\\n--- X cleaned ---\")\n",
    "print(f\"X (cleaned) shape: {X_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c786b863",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Splitting done ---\n",
      " Validation set (X_val, y_val) shape: (216592, 147), (216592,)\n",
      " Testing set (X_test, y_test) shape: (108296, 147), (108296,)\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 1.0 / 1.5 \n",
    "split_index = int(len(X_cleaned) * split_ratio)\n",
    "\n",
    "X_val = X_cleaned.iloc[:split_index]\n",
    "y_val = y.iloc[:split_index]\n",
    "\n",
    "X_test = X_cleaned.iloc[split_index:]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "print(f\"--- Data Splitting done ---\")\n",
    "print(f\" Validation set (X_val, y_val) shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\" Testing set (X_test, y_test) shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6573896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileClipper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower=0.005, upper=0.995):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.q_low_ = None\n",
    "        self.q_high_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.q_low_  = np.nanpercentile(X, self.lower * 100, axis=0) \n",
    "        self.q_high_ = np.nanpercentile(X, self.upper * 100, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.clip(X, self.q_low_, self.q_high_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd340eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = X_cleaned[SELECTED_FEATURES].copy()\n",
    "X_val = X_val[SELECTED_FEATURES].copy()\n",
    "X_test = X_test[SELECTED_FEATURES].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee709fae",
   "metadata": {},
   "source": [
    "### Applied Scaler only to raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature separation complete ---\n",
      "Will scale 44 'raw' columns (e.g., 'close', 'high'...)\n",
      "Will skip 103 'processed' columns (e.g., 'fz_...', 'dow_0'...)\n"
     ]
    }
   ],
   "source": [
    "def split_columns_for_scaling(X: pd.DataFrame):\n",
    "    # Regex to find already-processed columns\n",
    "    patterns = [\n",
    "        r'^fz_', r'_z_', r'(?:^|_)tanh', r'(?:^|_)arctanh',\n",
    "        r'(?:^|_)sin$', r'(?:^|_)cos$', r'^dow_\\d+$',\n",
    "        r'^has_news$', r'(?:^|_)log', r'(?:^|_)ln', r'(?:^|_)ewm',\n",
    "        r'^tone_', r'_flag$', r'_iqr_outlier$'\n",
    "    ]\n",
    "    regex = re.compile('|'.join(patterns))\n",
    "\n",
    "    name_matched = [c for c in X.columns if regex.search(c)]\n",
    "    # Find all 0/1 binary columns\n",
    "    binary_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 2]\n",
    "\n",
    "    no_scale_cols = sorted(set(name_matched + binary_cols))\n",
    "    scale_cols = [c for c in X.columns if c not in no_scale_cols]\n",
    "    return no_scale_cols, scale_cols\n",
    "\n",
    "no_scale_cols, scale_cols = split_columns_for_scaling(X_val)\n",
    "\n",
    "print(f\"--- Feature separation complete ---\")\n",
    "print(f\"Will scale {len(scale_cols)} 'raw' columns (e.g., 'close', 'high'...)\")\n",
    "print(f\"Will skip {len(no_scale_cols)} 'processed' columns (e.g., 'fz_...', 'dow_0'...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected features\n",
    "SELECTED_FEATURES ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544d66f",
   "metadata": {},
   "source": [
    "# Sequentially apply transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60  # 例如用过去 60 分钟\n",
    "PRED_HORIZON = 1\n",
    "\n",
    "def build_sequences(df, feature_cols, target_col, seq_len=SEQ_LEN):\n",
    "    X, y = [], []\n",
    "    for sym, g in df.groupby(\"symbol\"):\n",
    "        g = g.sort_values(\"datetime\")\n",
    "        feat = g[feature_cols].values\n",
    "        target = g[target_col].values\n",
    "        for i in range(len(g) - seq_len - PRED_HORIZON + 1):\n",
    "            X.append(feat[i:i+seq_len])\n",
    "            y.append(target[i+seq_len+PRED_HORIZON-1])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "X_seq_val, y_seq_val = build_sequences(df.loc[X_val.index], SELECTED_FEATURES, \"y_target\", seq_len=SEQ_LEN)\n",
    "X_seq_test, y_seq_test = build_sequences(df.loc[X_test.index], SELECTED_FEATURES, \"y_target\", seq_len=SEQ_LEN)\n",
    "\n",
    "def build_prefix_loaders(X_seq, y_seq, n_splits=10):\n",
    "    fold_sizes = np.linspace(0, len(X_seq), n_splits+1, dtype=int)\n",
    "    folds = []\n",
    "    for i in range(1, len(fold_sizes)):\n",
    "        train_end = fold_sizes[i]\n",
    "        val_end = fold_sizes[i] + max(1, fold_sizes[1])  # 让验证期与训练期后一段相邻\n",
    "        X_tr, y_tr = X_seq[:train_end], y_seq[:train_end]\n",
    "        X_va, y_va = X_seq[train_end:val_end], y_seq[train_end:val_end]\n",
    "        folds.append((\n",
    "            torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(y_tr)),\n",
    "                                        batch_size=BATCH_SIZE, shuffle=True),\n",
    "            torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(X_va), torch.from_numpy(y_va)),\n",
    "                                        batch_size=BATCH_SIZE, shuffle=False)\n",
    "        ))\n",
    "    return folds\n",
    "\n",
    "prefix_folds = build_prefix_loaders(X_seq_val, y_seq_val, n_splits=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff46c71",
   "metadata": {},
   "source": [
    "# Transformer Model (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6de6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ReturnTransformer(nn.Module):\n",
    "    def __init__(self, feature_dim, d_model=64, nhead=4, num_layers=2, ff_dim=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(feature_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            dim_feedforward=ff_dim, dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        enc = self.encoder(x)\n",
    "        return self.head(enc[:, -1, :]).squeeze(-1)\n",
    "def fit_transformer(folds, feature_dim, epochs=10, lr=1e-3):\n",
    "    best_models = []\n",
    "    for fold_id, (train_loader, val_loader) in enumerate(folds, 1):\n",
    "        model = ReturnTransformer(feature_dim)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        best_loss = float(\"inf\")\n",
    "        best_state = None\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "            val_loss = eval_epoch(model, val_loader, criterion)\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "        model.load_state_dict(best_state)\n",
    "        best_models.append(model)\n",
    "        print(f\"Fold {fold_id} best val MSE: {best_loss:.6f}\")\n",
    "    return best_models\n",
    "\n",
    "best_models = fit_transformer(prefix_folds, feature_dim=len(SELECTED_FEATURES), epochs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5973a17",
   "metadata": {},
   "source": [
    "## Training Loop using MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(xb)\n",
    "    return total_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e57a4bd",
   "metadata": {},
   "source": [
    "## Predicting and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a88813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequences(model, X_seq):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.from_numpy(X_seq)\n",
    "        return model(X_tensor).numpy()\n",
    "\n",
    "val_preds = predict_sequences(best_models[-1], X_seq_val)\n",
    "val_pnl = val_preds * y_seq_val\n",
    "print(\"Val Sharpe:\", calculate_sharpe(pd.Series(val_pnl)))\n",
    "\n",
    "test_preds = predict_sequences(best_models[-1], X_seq_test)\n",
    "test_pnl = test_preds * y_seq_test\n",
    "print(\"Test Sharpe:\", calculate_sharpe(pd.Series(test_pnl)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa5205-p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
